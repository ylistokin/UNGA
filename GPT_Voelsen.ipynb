{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# This file runs GPT 4o mini on the full text of each UN Resolution from 1994-2023 from the Voelsen database. It takes in two databases (one with the text of the resolution, (\"/content/gdrive/MyDrive/UNGA/fulltext.csv\") and the other with the other Voelsen data, main_data=pd.read_excel(\"/content/gdrive/MyDrive/UNGA/2024-03-13_unga-res_with_countries.xlsx\"), merges them and then merges the resulting data with the Un Watch data, (\"/content/gdrive/MyDrive/UNGA/UN Watch GA Resolutions 2015-August 2024.xlsx\") The file then runs GPT on the text and stores the resulting data as '/content/gdrive/MyDrive/UNGA/full_text_data2.csv'\n",
        "\n"
      ],
      "metadata": {
        "id": "XhgQo70FeuoG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "M0v93woxHUtD",
        "outputId": "5e58e4dc-86ab-4316-daaa-82bb03d09385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.2.6-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.13)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.137)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Collecting langchain-core<0.4.0,>=0.3.12 (from langchain)\n",
            "  Downloading langchain_core-0.3.15-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting openai<2.0.0,>=1.54.0 (from langchain_openai)\n",
            "  Downloading openai-1.54.3-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.10)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (0.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (4.66.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain_openai) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain) (3.0.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Downloading langchain_openai-0.2.6-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.15-py3-none-any.whl (408 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.7/408.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.54.3-py3-none-any.whl (389 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.6/389.6 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, openai, langchain-core, langchain_openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.52.2\n",
            "    Uninstalling openai-1.52.2:\n",
            "      Successfully uninstalled openai-1.52.2\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.13\n",
            "    Uninstalling langchain-core-0.3.13:\n",
            "      Successfully uninstalled langchain-core-0.3.13\n",
            "Successfully installed langchain-core-0.3.15 langchain_openai-0.2.6 openai-1.54.3 tiktoken-0.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1L4lgI5oRyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38e86a75-b248-4c5b-ef35-cfcb41a1af04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "# from langchain.embeddings import OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "AQq7wXEvH7_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#inputting two dataframes, both from Voeten et al. The first has the text of each post 1994 resolution, the second has voting and other info.\n",
        "text_data = pd.read_csv(\"/content/gdrive/MyDrive/UNGA/fulltext.csv\")\n",
        "\n",
        "main_data=pd.read_excel(\"/content/gdrive/MyDrive/UNGA/2024-03-13_unga-res_with_countries.xlsx\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dTiQOBccar7P",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#merging the two Voelsen datasets into one, using the unres variable.\n",
        "merged_data = pd.merge(text_data, main_data, on='unres', how='inner')\n"
      ],
      "metadata": {
        "id": "4b0JVOs_gYDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merger diagnostics\n",
        "print(merged_data.shape)\n",
        "missing_data = merged_data.isnull().sum()\n",
        "print(missing_data)\n",
        "\n",
        "# Check if all values in 'column1' and 'column2' are the same\n",
        "if (merged_data['vote_date_x'] == merged_data['vote_date_y']).all():\n",
        "    print(\"All observations have the same value in both columns.\")\n",
        "else:\n",
        "    print(\"There are differences between the columns.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_yh6BWhqi-J",
        "outputId": "8333d184-ddc0-46cc-8291-e40babf16870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9809, 301)\n",
            "url                           0\n",
            "detail_resolution_number_x    0\n",
            "unres                         0\n",
            "title_x                       0\n",
            "vote_date_x                   0\n",
            "                             ..\n",
            "Tokelau                       0\n",
            "Tonga                         0\n",
            "Tuvalu                        0\n",
            "Wallis_and_Futuna_Islands     0\n",
            "subjects_used_lower           0\n",
            "Length: 301, dtype: int64\n",
            "All observations have the same value in both columns.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  #Now merging with the un watch data.\n",
        "un_data=pd.read_excel(\"/content/gdrive/MyDrive/UNGA/UN Watch GA Resolutions 2015-August 2024.xlsx\")  #Reading in UN Watch data\n",
        "un_data.rename(columns={'Symbol': 'unres'}, inplace=True) #changing the resolution # to a common name for merging\n",
        "un_data['unres'] = un_data['unres'].str.replace('A/RES', 'R', regex=False)\n",
        "\n",
        "merged_data = pd.merge(merged_data, un_data, on='unres', how='left')\n",
        "merged_data.shape\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdKOGievANcC",
        "outputId": "243d0c5c-e266-42a3-f208-39f1a2ec51f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9809, 308)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using OpenAI and api models\n",
        "\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "            model_name='gpt-4o-mini',\n",
        "            temperature=0.5,\n",
        "            streaming=True,\n",
        "            openai_api_key=\\",\n",
        "            max_tokens=2500)"
      ],
      "metadata": {
        "id": "5Nl3QuO6JCFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"You are an AI assistant with expertise in international relations, law, and political science.\n",
        "Your task is to analyze the text of resolutions issued by the UN General Assembly\n",
        "and identify if a specific country is being condemned or criticized by the UN resolution.\n",
        "For each General Assembly Resolution I provide, please return only the name of the specific country being criticized.\n",
        "If no specific country is being criticized, return \"None\": {text}\"\"\"\n",
        "\n",
        "\n",
        "def run_sentiment_analysis(text):\n",
        "    prompt = PromptTemplate(input_variables=[\"text\"], template=prompt_template)\n",
        "\n",
        "\n",
        "    llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "\n",
        "    result = llm_chain.run(text)\n",
        "\n",
        "\n",
        "    return result\n",
        "\n"
      ],
      "metadata": {
        "id": "dUklp-AaJXN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the new variable (column) with default values for testing\n",
        "merged_data['country'] = ''\n",
        "\n",
        "# Apply the sentiment analysis function to the 'text' column\n",
        "merged_data['country'] = merged_data['text'].apply(run_sentiment_analysis)"
      ],
      "metadata": {
        "id": "jrJZ5Ju7Uy_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a62c7e-e859-4e55-c47e-21678f62fd26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d3d68516ff2a>:12: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
            "<ipython-input-10-d3d68516ff2a>:15: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = llm_chain.run(text)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data['country'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "3Zqj3AbH-8rL",
        "outputId": "4b14d23f-ad3e-4521-f06e-4db7e56d0172",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "country\n",
              "None                                                    8572\n",
              "Israel                                                   536\n",
              "United States of America                                  87\n",
              "United Kingdom of Great Britain and Northern Ireland      59\n",
              "Democratic People’s Republic of Korea                     49\n",
              "                                                        ... \n",
              "Armenia                                                    1\n",
              "India, Israel, Pakistan                                    1\n",
              "Uzbekistan                                                 1\n",
              "Ecuador                                                    1\n",
              "South Africa                                               1\n",
              "Name: count, Length: 80, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>country</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>None</th>\n",
              "      <td>8572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Israel</th>\n",
              "      <td>536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>United States of America</th>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>United Kingdom of Great Britain and Northern Ireland</th>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Democratic People’s Republic of Korea</th>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Armenia</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>India, Israel, Pakistan</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Uzbekistan</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ecuador</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>South Africa</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Practicing saving files to google drive\n",
        "# Define the file path in your Google Drive\n",
        "file_path = '/content/gdrive/MyDrive/UNGA/full_text_data2.csv'\n",
        "\n",
        "# Save the DataFrame to the file path as a CSV\n",
        "merged_data.to_csv(file_path, index=False)\n",
        "\n",
        "print(f'DataFrame saved to {file_path}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAkyCxvEEHJp",
        "outputId": "9ec554eb-8868-450d-9aa2-93889a8e82d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to /content/gdrive/MyDrive/UNGA/full_text_data2.csv\n"
          ]
        }
      ]
    }
  ]
}